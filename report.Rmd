---
title: "Laboratory of Customer and Business Analytics - Smartphones Report"
author: "Dall'Asen Nicola - Debeni Andrea - Zorzoni Riccardo"
date: "12/21/2020"
output:
  html_document: default
  pdf_document: default
---

# Introduction

The aim of this study is to provide an insight on the most important features that customer take into consideration when they choose a new smartphone, in order to provide market segments and analyze customers' tastes.
The study has been conducted through the use of a choice-based conjoint analysis on data collected through an online survey thanks to the statistical tool of Multinomial Logistic Regression and Bootstrap prediction.

## Data collection

### Method used
...

### Data preprocessing
...

# Data Analysis

```{r import, results='hide'}
library(mlogit)
library(parallel)
library(MASS)
```

### Data loading and cleaning

```{r loading}
smartphones.df <- read.csv("final.csv", sep=",")
names(smartphones.df) <- c("X", "smart.id", "quest.id", "smart.name", "profile", "price", "ram.storage", "os", "display", "dailyuse", "camera", "battery", "resp.id", "choice")
# Filter needed columns
to_keep_cols <- c("resp.id", "quest.id", "profile", "price", "ram.storage", "os", "display", "dailyuse", "camera", "battery", "choice")
smartphones.df <- smartphones.df[,to_keep_cols]
# mlogit requires every question to have a different ID
smartphones.df$quest.id <- rep(1:1417, each= 3)

# recode some variables
smartphones.df$price <- as.factor(smartphones.df$price)
smartphones.df$ram.storage <- factor(smartphones.df$ram.storage, levels = c("4/64", "8/128", "12/256"))
smartphones.df$os <- factor(smartphones.df$os)
smartphones.df$display <- factor(smartphones.df$display, levels = c("Low", "Medium", "High"))
smartphones.df$dailyuse <- factor(smartphones.df$dailyuse, levels = c("Low", "Medium", "High"))
smartphones.df$camera <- factor(smartphones.df$camera, levels = c("Low", "Medium", "High"))
smartphones.df$battery <- factor(smartphones.df$battery, levels = c("Low", "Medium", "High"))
smartphones.df$profile <- as.factor(smartphones.df$profile)
```

## Fixed MNL

```{r convert}
# convert data to the format accepted by mlogit
smartphones.mlogit <- dfidx(smartphones.df, idx = list(c("quest.id", "resp.id"), "profile"), drop.index=F,
                        levels=c("1", "2", "3"))
```

```{r fmnl, results='hide'}
# Fit the mlogit model to the data
fmnl.intercept <- mlogit(choice ~ price + ram.storage + os + display + 
               dailyuse + camera + battery, data = smartphones.mlogit)
summary(fmnl.intercept)
```

```{r fmnl_no_intercept}
# Fit the model without intercept parameters
fmnl.no.intercept <- mlogit(choice ~ price + ram.storage + os + display + 
               dailyuse + camera + battery | -1, data = smartphones.mlogit)
summary(fmnl.no.intercept)
```

```{r lrtest_1}
# Test the restriction on the intercepts by comparing the two models through a likelihood ratio test
lrtest(fmnl.no.intercept, fmnl.intercept)
```

```{r fmnl_price_quantitative, results='hide'}
# Fit the model without intercept parameters and with price as a quantitative variable
fmnl.no.intercept.quantitative <- mlogit(choice ~ as.numeric(as.character(price)) + ram.storage + os + display + dailyuse + camera + battery | -1, data = smartphones.mlogit)
summary(fmnl.no.intercept.quantitative)
```

```{r lrtest_2}
lrtest(fmnl.no.intercept.quantitative, fmnl.no.intercept)
```

With the last model, having price as a quantitative variable, we can compute the willingness to pay for some features (let's keep the highest??? dunno)

```{r willingness}
#coef(m3)["ram.storage8/128"]/(coef(m3)["as.numeric(as.character(price))"])
#coef(fmnl.no.intercept.quantitative)["ram.storage12/256"]/(coef(fmnl.no.intercept.quantitative)["as.numeric(as.character(price))"])
coef(fmnl.no.intercept.quantitative)["osiOS"]/(coef(fmnl.no.intercept.quantitative)["as.numeric(as.character(price))"])
#coef(m3)["displayMedium"]/(coef(m3)["as.numeric(as.character(price))"])
#coef(fmnl.no.intercept.quantitative)["displayHigh"]/(coef(fmnl.no.intercept.quantitative)["as.numeric(as.character(price))"])
#coef(m3)["dailyuseMedium"]/(coef(m3)["as.numeric(as.character(price))"])
#coef(fmnl.no.intercept.quantitative)["dailyuseHigh"]/(coef(fmnl.no.intercept.quantitative)["as.numeric(as.character(price))"])
#coef(m3)["cameraMedium"]/(coef(m3)["as.numeric(as.character(price))"])
coef(fmnl.no.intercept.quantitative)["cameraHigh"]/(coef(fmnl.no.intercept.quantitative)["as.numeric(as.character(price))"])
#coef(m3)["batteryMedium"]/(coef(m3)["as.numeric(as.character(price))"])
coef(fmnl.no.intercept.quantitative)["batteryHigh"]/(coef(fmnl.no.intercept.quantitative)["as.numeric(as.character(price))"])
```

Instead of keeping this amount of levels for the price variable, we group it into the 5 categories explained at the beginning 

```{r new_data}
tmp.df <- smartphones.df
tmp.df$price <- as.numeric(as.character(tmp.df$price))
tmp.df$price <- cut(tmp.df$price, c(-Inf, 200, 300, 500, 900, Inf), c("L","ML", "M", "MH", "H"))
tmp.df$price <- factor(tmp.df$price, levels = c("L","ML", "M", "MH", "H"))

updated.smartphones.mlogit <- dfidx(tmp.df, idx = list(c("quest.id", "resp.id"), "profile"), drop.index=F,
                            levels=c("1", "2", "3"))
```

We then fit a new model without intercept on these new data

```{r fmnl.no.intercepet.ranges}
fmnl.no.intercept.ranges <- mlogit(choice ~ price + ram.storage + os + display + 
               dailyuse + camera + battery | -1, data = updated.smartphones.mlogit)
summary(fmnl.no.intercept.ranges)
```

```{r generate_designs}
attributes <- list(ram.storage=names(table(updated.smartphones.mlogit$ram.storage)),
               os=names(table(updated.smartphones.mlogit$os)),
               display=names(table(updated.smartphones.mlogit$display)),
               dailyuse=names(table(updated.smartphones.mlogit$dailyuse)),
               camera=names(table(updated.smartphones.mlogit$camera)),
               battery=names(table(updated.smartphones.mlogit$battery)),
               price=names(table(updated.smartphones.mlogit$price)))
all.designs <- expand.grid(attributes) 
```

We then choose a reasonable amount of profiles for every price range and determing the preference shares separately, the "best" profiles for every category are then compared

```{r preference_by_price}
all.designs.low <- all.designs[all.designs$price=="L" & all.designs$os=="Android" & all.designs$ram.storage=="4/64",]
row.names(all.designs.low) <- NULL
new.data.low <- all.designs.low[c(67, 55, 68, 59, 32, 40, 31, 38, 41, 14, 23),]

all.designs.mlow <- all.designs[all.designs$price=="ML" & all.designs$os=="Android" & all.designs$ram.storage!="12/256",]
row.names(all.designs.mlow) <- NULL
new.data.medium.low <- all.designs.mlow[c(143, 136, 119, 144, 132, 120, 88, 47, 48, 134, 83, 122, 11, 94),]

all.designs.medium <- all.designs[all.designs$price=="M" & all.designs$os=="Android" & all.designs$ram.storage=="8/128",]
row.names(all.designs.medium) <- NULL
new.data.medium <- all.designs.medium[c(45, 69, 44, 68, 36, 60, 17, 18, 72),]

all.designs.mhigh <- all.designs[all.designs$price=="MH",]
row.names(all.designs.mhigh) <- NULL
new.data.medium.high <- all.designs.mhigh[c(319, 322, 242, 245, 302, 305, 249, 252, 320, 476, 297, 321, 429, 411),]

all.designs.high <- all.designs[all.designs$price=="H" & all.designs$ram.storage!="4/64",]
row.names(all.designs.high) <- NULL
new.data.high <- all.designs.high[c(202, 204, 213, 215, 94, 96, 178, 165, 18, 95, 20, 92, 90, 173, 175),]
```

```{r pred_def, echo=FALSE}
predict.mnl <- function(model, data) {
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
  logitUtility <- data.model%*%model$coef
  share <- exp(logitUtility)/sum(exp(logitUtility))
  cbind(share, data)
}
```

```{r pred_boot, echo=FALSE}
BootCI.predict.mnl <- function(model, data, nsim=500, conflevel=0.95) {
  dataModel <- model$model
  dataModel$probabilities <- NULL
  dataModel$linpred <- NULL
  idx <- dataModel$idx 
  dataModel$idx <- NULL
  dataModel <- data.frame(dataModel, idx)
  idVar <- unique(dataModel[,names(idx)[1]])
  
  bootstrapping <- function(x) {
    idbootsamp <- data.frame(sample(idVar, replace=T))
    names(idbootsamp) <- names(idx)[1]
    bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
    bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,3])))
    bootsamp.mlogit  <- dfidx(bootsamp, idx = list(c(names(idx)[1:2]), names(idx)[3]),
                              drop.index=F)    
    bootfit <- update(model, data = bootsamp.mlogit)
    data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = data)[,-1]
    logitUtility <- data.model%*%bootfit$coef
    share <- exp(logitUtility)/sum(exp(logitUtility))
    share
  }
  
  cl <- makeCluster(detectCores())
  clusterEvalQ(cl, library(mlogit))
  clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "model", "data"), 
                envir=environment())
  bootdistr <- parLapply(cl, 1:nsim, fun=bootstrapping)
  stopCluster(cl)
  
  bootdistr <- do.call(cbind, bootdistr)
  lowl <- (1-conflevel)/2
  upl <- 1-lowl  
  bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
  pointpred <- predict.mnl(model, data)
  predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
  names(predictedShares)[1] <- "share" 
  predictedShares
}
```


```{r pref, echo=FALSE, results="hide"}
# We then pass these designs to predict.mnl() to determine what customers
# would choose if they had to pick among these smartphones alternatives:
predict.mnl(fmnl.no.intercept.ranges, new.data.low) 
predict.mnl(fmnl.no.intercept.ranges, new.data.medium.low)
predict.mnl(fmnl.no.intercept.ranges, new.data.medium) 
predict.mnl(fmnl.no.intercept.ranges, new.data.medium.high) 
predict.mnl(fmnl.no.intercept.ranges, new.data.high) 
```

The best for each category are then taken into account for the last preference share prediction

```{r best_pref}
new.data <- all.designs[c(403, 223, 878, 914, 1400, 1382, 1887, 1779, 1763, 2267, 2250, 2264),]
predict.mnl(fmnl.no.intercept.ranges, new.data)
```

To have more statistical-relevant results let's calculate confidence intervals for the shares

```{r best_pref_boot}
BootCI.predict.mnl(fmnl.no.intercept.ranges, new.data)
```


```{r sensitivity, echo=FALSE}
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
  # Function for creating data for a preference share-sensitivity chart
  # model: mlogit object returned by mlogit() function
  # attrib: list of vectors with attribute levels to be used in sensitivity
  # base.data: data frame containing baseline design of target product
  # competitor.data: data frame contining design of competitive set
  data <- rbind(base.data, competitor.data)
  base.share <- predict.mnl(model, data)[1,1]
  share <- NULL
  for (a in seq_along(attrib)) {
    for (i in attrib[[a]]) {
      data[1,] <- base.data
      data[1,a] <- i
      share <- c(share, predict.mnl(model, data)[1,1])
    }
  }
  data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}
```

### Calculate and plot sensitivity

```{r plot_sensitivity}
base.data <- new.data[1,]
competitor.data <- new.data[-1,]
(tradeoff <- sensitivity.mnl(fmnl.no.intercept.ranges, attributes, base.data, competitor.data))

barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
        ylab="Change in Share for the Planned Product Design", 
        ylim=c(-0.1,0.11))
grid(nx=NA, ny=NULL)
```

## Control for customers' heterogeneity 

Let's fit a MMNL model in order to check for customers' heterogeneity

```{r rpar}
model.random.parameters <- rep("n", length=length(fmnl.no.intercept.ranges$coef))
names(model.random.parameters) <- names(fmnl.no.intercept.ranges$coef)
```

```{r mmnl_fit}
m.mixed <- mlogit(choice ~ price + ram.storage + os + display + 
                     dailyuse + camera + battery | -1, data = updated.smartphones.mlogit,
                  panel=TRUE, rpar = model.random.parameters, correlation = FALSE)
summary(m.mixed)
```

```{r plot_mixed}
plot(m.mixed)
```

We can add correlation among variables to the model

```{r mixed_correlation, results='hide'}
m.mixed.cor <- update(m.mixed, correlation = TRUE)
summary(m.mixed.cor)

cov2cor(cov.mlogit(m.mixed.cor))

summary(vcov(m.mixed.cor, what = "rpar", type = "cor"))
```

And then restrict to have correlation only among few of them

```{r mixed_correlation_reduced}
m.mixed.cor.reduced <- update(m.mixed.cor, correlation = c("ram.storage12/256", "osiOS",
                                             "displayHigh", "batteryMedium", "batteryHigh", "cameraHigh"))
```

With the likelihood ration test we can compare these models

```{r mixed_lr_test}
lrtest(fmnl.no.intercept.ranges, m.mixed) #Fixed effects vs. uncorrelated random effects
lrtest(m.mixed, m.mixed.cor) #Uncorrelated random effects vs. all correlated random effects
lrtest(m.mixed.cor.reduced, m.mixed.cor) #partially correlated random effects vs. all correlated random effects
```

We can now compute preference share in the MMNL model

```{r pred_mmnl, echo=FALSE}
predict.mixed.mnl <- function(model, data, nresp=1000) {
  # Function for predicting shares from a mixed MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares. Same format at the data used to estimate model. 
  # Note that this code assumes all model parameters are random
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
  coef.Sigma <- cov.mlogit(model)
  coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
  draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
  shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
  for (i in 1:nresp) {
    utility <- data.model%*%draws[i,]
    share = exp(utility)/sum(exp(utility))
    shares[i,] <- share
  }
  cbind(colMeans(shares), data)
}
```

```{r boot_mmnl_def, echo=FALSE}
BootCI.predict.mixed.mnl <- function(model, data, nsim=500, conflevel=0.95, nresp=1000) {
  dataModel <- model$model
  dataModel$probabilities <- NULL
  dataModel$linpred <- NULL
  idx <- dataModel$idx 
  dataModel$idx <- NULL
  dataModel <- data.frame(dataModel, idx)
  idVar <- unique(dataModel[,names(idx)[1]])
  
  bootstrapping <- function(x) {
    idbootsamp <- data.frame(sample(idVar, replace=T))
    names(idbootsamp) <- names(idx)[1]
    bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
    bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,3])))
    bootsamp.mlogit  <- dfidx(bootsamp, idx = list(c(names(idx)[1:2]), names(idx)[3]),
                              drop.index=F)    
    bootfit <- update(model, data = bootsamp.mlogit)
    data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = data)[,-1]
    coef.Sigma <- cov.mlogit(bootfit)
    coef.mu <- bootfit$coef[1:dim(coef.Sigma)[1]]
    draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
    shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
    for (i in 1:nresp) {
      utility <- data.model%*%draws[i,]
      share <- exp(utility)/sum(exp(utility))
      shares[i,] <- share
    }
    colMeans(shares)
  }
  
  cl <- makeCluster(detectCores())
  clusterEvalQ(cl, {
    library(mlogit)
    library(MASS) })
  clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "model", "data", "nresp", 
                              paste(model$call$rpar)), envir=environment())
  bootdistr <- parLapply(cl, 1:nsim, fun=bootstrapping)
  stopCluster(cl)
  
  bootdistr <- do.call(cbind, bootdistr)
  lowl <- (1-conflevel)/2
  upl <- 1-lowl  
  bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
  pointpred <- predict.mixed.mnl(model, data, nresp)
  predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
  names(predictedShares)[1] <- "share" 
  predictedShares
}
```

```{r predict_mmnl}
predict.mixed.mnl(m.mixed.cor, data=new.data)
```

And compute confidence intervals

```{r boot_mmnl}
BootCI.predict.mixed.mnl(m.mixed.cor, data=new.data, nresp = 3, nsim = 3)
```

